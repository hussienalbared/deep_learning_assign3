{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from load_mnist import load_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##b) Vanishing Gradients and Initialization (9 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset():\n",
    "    def __init__(self, dataset, subset=None, sorted=False, path=\"data/FashionMNIST/raw\"):\n",
    "        # Load data\n",
    "        images, labels = load_mnist(path=path, dataset=dataset)\n",
    "        self.x = images\n",
    "        self.y = labels.long()  \n",
    "\n",
    "        # Include only specified labels\n",
    "        if subset is not None:\n",
    "            indices = th.nonzero(reduce(lambda x, y: x | y, map(lambda x: labels == x, subset)))[:,0]\n",
    "            self.x = self.x[indices]\n",
    "            self.y = self.y[indices]\n",
    "\n",
    "        # Sort labels\n",
    "        if sorted is True:\n",
    "            indices = th.argsort(self.y)\n",
    "            self.x = self.x[indices]\n",
    "            self.y = self.y[indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Preprocess the image\n",
    "        image = self.x[index]\n",
    "        image = 2.0*(image/255.0)-1.0\n",
    "        #image = (image-self.mean/self.std)\n",
    "        return image, self.y[index]\n",
    "\n",
    "\n",
    "\n",
    "class FashionMNISTClassifier(th.nn.Module):\n",
    "\n",
    "    def __init__(self, num_neurons=[50, 20], activation=th.nn.ReLU):\n",
    "        super().__init__()\n",
    "        num_neurons = [784] + num_neurons\n",
    "\n",
    "        self.layers = th.nn.ModuleList()\n",
    "        self.layers.append(th.nn.Flatten())\n",
    "        for i, in_neurons in enumerate(num_neurons[:-1]):\n",
    "            out_neurons = num_neurons[i+1]\n",
    "            self.layers.append(th.nn.Linear(in_neurons, out_neurons, True))\n",
    "            self.layers.append(activation())\n",
    "        self.layers.append(th.nn.Linear(num_neurons[-1], 10, True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class Swish(th.nn.Module):\n",
    "\n",
    "    def __init__(self, beta=1.0) -> None:\n",
    "        super().__init__()\n",
    "        self.beta  = th.nn.Parameter(th.tensor(beta))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * th.sigmoid(self.beta * x)\n",
    "\n",
    "def train(model, criterion, dataloader, optimizer):\n",
    "    avgLoss = 0\n",
    "    norms=[]\n",
    "    for index, (images, labels) in enumerate(dataloader):\n",
    "        # print(index)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(images)\n",
    "        loss = criterion(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with th.no_grad():\n",
    "            avgLoss += loss.numpy()/len(dataloader)\n",
    "            \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            norms.append(param.data.norm(2).item())\n",
    "            \n",
    "         \n",
    "    return avgLoss,norms\n",
    "\n",
    "def accuracy(predicted, true):\n",
    "    return th.mean((predicted == true).type(th.float32))\n",
    "\n",
    "@th.no_grad()\n",
    "def evaluate(model, images, labels):\n",
    "    model.eval()\n",
    "    predictions = model(images)\n",
    "    _, predictions = th.max(predictions, dim=1)\n",
    "    return accuracy(predictions, labels)\n",
    "    \n",
    "\n",
    "def run_configuration(activation=th.nn.Sigmoid):\n",
    "    configurations=[[50],[50,30],[50,30,30],[50,30,30,30]]\n",
    "    # configurations=[[50,30]]\n",
    "    for configuration in configurations:\n",
    "        criterion = th.nn.CrossEntropyLoss()\n",
    "        testset = Dataset('testing')\n",
    "        \n",
    "        model = FashionMNISTClassifier(num_neurons=configuration,activation=activation)\n",
    "        optimizer = th.optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "        losses_a = [float('nan')]*5\n",
    "        accuarcies_a = [float('nan')]*5\n",
    "        norms_a=[]\n",
    "        \n",
    "\n",
    "        dataset = Dataset('training')\n",
    "        dataloader = th.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        for epoch in range(5):\n",
    "                loss,norms = train(model, criterion, dataloader, optimizer)\n",
    "                accuarcy = evaluate(model, testset.x, testset.y)\n",
    "                losses_a[epoch] = loss\n",
    "                accuarcies_a[epoch] = accuarcy\n",
    "                norms_a.append(norms)\n",
    "                print('accuracy :{}'.format(accuarcy.data))\n",
    "                print('norms :{}'.format(norms))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b 1\n",
    "Take your FashionMNIST classifier from the last exercise sheet and train\n",
    "it for 20 epochs with the following layer configurations: (50,), (50, 30), (50, 30,\n",
    "30), (50, 30, 30, 30). Your net should have torch.nn.Sigmoid as the activation\n",
    "function between all hidden layers. Use the torch.optim.SGD optimizer with a learning\n",
    "rate of Î· = 0:005. Record the norms of the gradients (per layer) of the last batch each\n",
    "iteration as well as the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :0.328900009393692\n",
      "norms :[4.360305309295654, 0.12342795729637146, 2.4818596839904785, 0.19532305002212524]\n",
      "accuracy :0.47380000352859497\n",
      "norms :[4.677216529846191, 0.1265179067850113, 3.367706298828125, 0.19616451859474182]\n",
      "accuracy :0.5703999996185303\n",
      "norms :[4.944694995880127, 0.12945617735385895, 4.050527572631836, 0.1970328688621521]\n",
      "accuracy :0.6114000082015991\n",
      "norms :[5.168910026550293, 0.13169535994529724, 4.581873893737793, 0.19733576476573944]\n",
      "accuracy :0.6284999847412109\n",
      "norms :[5.3591437339782715, 0.13351227343082428, 5.0078864097595215, 0.2006649523973465]\n",
      "accuracy :0.25519999861717224\n",
      "norms :[4.1063385009765625, 0.1466086506843567, 3.159876823425293, 0.45604872703552246, 1.8135693073272705, 0.40482398867607117]\n",
      "accuracy :0.31139999628067017\n",
      "norms :[4.138560771942139, 0.14627180993556976, 3.2075109481811523, 0.45394542813301086, 1.8992550373077393, 0.4069543778896332]\n",
      "accuracy :0.3066999912261963\n",
      "norms :[4.2032575607299805, 0.1457388550043106, 3.3157589435577393, 0.4497404098510742, 2.0875256061553955, 0.40649712085723877]\n",
      "accuracy :0.29840001463890076\n",
      "norms :[4.310355186462402, 0.14554812014102936, 3.524557113647461, 0.4430604577064514, 2.435056447982788, 0.413129985332489]\n",
      "accuracy :0.30869999527931213\n",
      "norms :[4.443016052246094, 0.14601019024848938, 3.8181850910186768, 0.4362044334411621, 2.9138612747192383, 0.41630250215530396]\n",
      "accuracy :0.09939999878406525\n",
      "norms :[4.066259384155273, 0.14814336597919464, 3.2384374141693115, 0.4147067666053772, 3.1598780155181885, 0.5200150609016418, 1.7785414457321167, 0.3397490978240967]\n",
      "accuracy :0.08950000256299973\n",
      "norms :[4.066904067993164, 0.14812807738780975, 3.239267587661743, 0.4147202968597412, 3.1607327461242676, 0.5200908780097961, 1.7796331644058228, 0.3423500061035156]\n",
      "accuracy :0.16910000145435333\n",
      "norms :[4.068039894104004, 0.1481095254421234, 3.240753412246704, 0.4147583842277527, 3.1621415615081787, 0.520024299621582, 1.782997488975525, 0.3396546542644501]\n",
      "accuracy :0.2529999911785126\n",
      "norms :[4.069724082946777, 0.1480892300605774, 3.2429752349853516, 0.4148498773574829, 3.1645617485046387, 0.519949197769165, 1.7869354486465454, 0.3409900367259979]\n",
      "accuracy :0.21379999816417694\n",
      "norms :[4.072028160095215, 0.14807265996932983, 3.2460389137268066, 0.4149099588394165, 3.16780161857605, 0.5199622511863708, 1.792921543121338, 0.34034430980682373]\n",
      "accuracy :0.10000000149011612\n",
      "norms :[4.073092937469482, 0.14044369757175446, 3.1518728733062744, 0.46576550602912903, 3.0829410552978516, 0.5132693648338318, 3.1718008518218994, 0.4886535406112671, 1.7439830303192139, 0.41113653779029846]\n",
      "accuracy :0.10000000149011612\n",
      "norms :[4.073090553283691, 0.14044156670570374, 3.151867389678955, 0.46576136350631714, 3.0829548835754395, 0.5132456421852112, 3.171713352203369, 0.4884079098701477, 1.744228482246399, 0.40965235233306885]\n",
      "accuracy :0.10270000249147415\n",
      "norms :[4.073092460632324, 0.14043991267681122, 3.151869297027588, 0.4657612442970276, 3.0829451084136963, 0.5132191777229309, 3.1718006134033203, 0.48849841952323914, 1.743959665298462, 0.410776823759079]\n",
      "accuracy :0.10000000149011612\n",
      "norms :[4.073100566864014, 0.14043818414211273, 3.151876211166382, 0.4657560884952545, 3.082974672317505, 0.5132366418838501, 3.1716887950897217, 0.4883710741996765, 1.7437975406646729, 0.4114982485771179]\n",
      "accuracy :0.10000000149011612\n",
      "norms :[4.073111057281494, 0.14043612778186798, 3.1518890857696533, 0.46575745940208435, 3.0829789638519287, 0.5132324695587158, 3.1717376708984375, 0.48845499753952026, 1.7437613010406494, 0.4115890860557556]\n"
     ]
    }
   ],
   "source": [
    "run_configuration(activation=th.nn.Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b 3\n",
    "Rerun the above experiment, this time using torch.nn.ReLU as the activation\n",
    "function. Also plot the results like above. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :0.6085000038146973\n",
      "norms :[4.467549800872803, 0.15378272533416748, 2.586721181869507, 0.26340410113334656]\n",
      "accuracy :0.6384000182151794\n",
      "norms :[4.654330253601074, 0.1561964452266693, 2.8958637714385986, 0.26427319645881653]\n",
      "accuracy :0.6601999998092651\n",
      "norms :[4.788599491119385, 0.1575445532798767, 3.104959011077881, 0.2659487724304199]\n",
      "accuracy :0.6690999865531921\n",
      "norms :[4.896921157836914, 0.15873202681541443, 3.266948699951172, 0.26688724756240845]\n",
      "accuracy :0.6833000183105469\n",
      "norms :[4.987635612487793, 0.15988647937774658, 3.3984928131103516, 0.2691066265106201]\n",
      "accuracy :0.5361999869346619\n",
      "norms :[4.419488906860352, 0.16360044479370117, 3.5687403678894043, 0.42819544672966003, 2.490389347076416, 0.44874975085258484]\n",
      "accuracy :0.5953999757766724\n",
      "norms :[4.6322407722473145, 0.16714532673358917, 3.828632354736328, 0.4302278161048889, 2.8529419898986816, 0.46018487215042114]\n",
      "accuracy :0.6150000095367432\n",
      "norms :[4.746358394622803, 0.16782069206237793, 3.9650533199310303, 0.4305194318294525, 3.035588026046753, 0.4646778106689453]\n",
      "accuracy :0.6284000277519226\n",
      "norms :[4.837369918823242, 0.16834312677383423, 4.072197914123535, 0.4299442172050476, 3.1756598949432373, 0.46866801381111145]\n",
      "accuracy :0.6377000212669373\n",
      "norms :[4.916847229003906, 0.1686994433403015, 4.164544105529785, 0.4298228919506073, 3.2942957878112793, 0.4726668894290924]\n",
      "accuracy :0.4059000015258789\n",
      "norms :[4.317195415496826, 0.14419671893119812, 3.3973231315612793, 0.48228374123573303, 3.3984498977661133, 0.6431517601013184, 2.343801736831665, 0.27251577377319336]\n",
      "accuracy :0.5875999927520752\n",
      "norms :[4.55973482131958, 0.14681674540042877, 3.699849843978882, 0.48513147234916687, 3.7018961906433105, 0.6539320945739746, 2.7715721130371094, 0.29771968722343445]\n",
      "accuracy :0.6258999705314636\n",
      "norms :[4.6562371253967285, 0.14901725947856903, 3.81672739982605, 0.4831297695636749, 3.8191184997558594, 0.6559996008872986, 2.9311130046844482, 0.30816054344177246]\n",
      "accuracy :0.6445000171661377\n",
      "norms :[4.721674919128418, 0.15079477429389954, 3.8942723274230957, 0.4825482666492462, 3.8969945907592773, 0.6566747426986694, 3.0360634326934814, 0.3137759566307068]\n",
      "accuracy :0.6568999886512756\n",
      "norms :[4.78231954574585, 0.15158246457576752, 3.9649107456207275, 0.482576459646225, 3.9677987098693848, 0.6578615307807922, 3.1300837993621826, 0.31963276863098145]\n",
      "accuracy :0.19380000233650208\n",
      "norms :[4.103063106536865, 0.16130700707435608, 3.226604461669922, 0.4395909607410431, 3.092722177505493, 0.5966050028800964, 3.2355844974517822, 0.5725529789924622, 1.7978429794311523, 0.28219664096832275]\n",
      "accuracy :0.39969998598098755\n",
      "norms :[4.244521617889404, 0.15451082587242126, 3.404165744781494, 0.4574890434741974, 3.280003070831299, 0.668427050113678, 3.428314208984375, 0.7122032046318054, 2.167208194732666, 0.27554839849472046]\n",
      "accuracy :0.5232999920845032\n",
      "norms :[4.449579238891602, 0.15630172193050385, 3.655637264251709, 0.46630796790122986, 3.54136061668396, 0.6799998879432678, 3.68149471282959, 0.7452877759933472, 2.562627077102661, 0.3496914207935333]\n",
      "accuracy :0.5022000074386597\n",
      "norms :[4.5311994552612305, 0.15833847224712372, 3.7523372173309326, 0.4664371907711029, 3.6407721042633057, 0.6817481517791748, 3.7779288291931152, 0.7461567521095276, 2.7070112228393555, 0.37480586767196655]\n",
      "accuracy :0.5174000263214111\n",
      "norms :[4.609880447387695, 0.15927673876285553, 3.843158483505249, 0.4663560390472412, 3.7337398529052734, 0.682866096496582, 3.8681623935699463, 0.7452272772789001, 2.838364839553833, 0.3926420509815216]\n"
     ]
    }
   ],
   "source": [
    "run_configuration(activation=th.nn.ReLU)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d561781319b90a9d861033d98564cee4f58857c6d3182aa102dcb17c7da61679"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('computer-vision': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
